# Prompt Log

**Timestamp:** 2026-02-27T01:11:55.062Z
**Persona:** test_engineer
**Model:** gpt-4.1

## Prompt

```
**Task**: **YOUR TASK**: Design, implement, or review end-to-end test strategies and implementations for web applications, with focus on browser automation, visual testing, and user journey validation.

**Project Context:**
- Project: /home/mpb/Documents/GitHub/paraty_geocore.js ()
- Project Type: 
- E2E Framework: 
- Test Command: 
- Browser Targets: 
- Modified Files: 

**ANALYSIS PHASE**: Evaluate existing E2E test coverage for:
1. **User Journey Coverage**: Critical paths, authentication, checkout, forms, navigation
2. **Visual Testing**: Screenshot comparison, layout validation, responsive breakpoints
3. **Browser Compatibility**: Cross-browser test coverage, device emulation
4. **Test Reliability**: Flakiness patterns, wait strategies, test data management
5. **Performance Testing**: Page load metrics, Core Web Vitals, interaction timing
6. **Accessibility Validation**: Automated accessibility checks, keyboard navigation tests
7. **Test Infrastructure**: CI/CD integration, parallel execution, test reporting
8. **Test Maintainability**: Page Object patterns, test data fixtures, reusable utilities

**REQUIRED ACTIONS**:

1. **E2E Test Strategy & Implementation:**
   - Identify critical user journeys requiring E2E coverage
   - Design test scenarios covering happy paths and edge cases
   - Implement Page Object Model (POM) or equivalent pattern
   - Create reusable test utilities and helper functions
   - Structure tests for maintainability (setup, action, assertion, teardown)
   - Implement proper test isolation and cleanup
   - Use data-testid attributes for stable selectors
   - Avoid coupling tests to implementation details

2. **Visual Testing Implementation:**
   - Implement screenshot comparison tests for critical UI states
   - Validate layout across responsive breakpoints (mobile, tablet, desktop)
   - Test visual consistency across browsers
   - Implement visual regression detection
   - Configure screenshot thresholds and ignore regions
   - Test dark mode and theme variations
   - Validate design system component consistency
   - Compare actual UI against design specifications

3. **Browser Automation & Cross-Browser Testing:**
   - Configure tests to run on multiple browsers (Chrome, Firefox, Safari, Edge)
   - Implement device emulation for mobile testing (iPhone, Android devices)
   - Test browser-specific features and fallbacks
   - Handle browser-specific quirks and timing issues
   - Configure headless mode for CI/CD environments
   - Test different viewport sizes and orientations
   - Validate touch interactions on mobile devices
   - Test Progressive Web App (PWA) functionality

4. **User Journey & Workflow Testing:**
   - Test multi-step workflows (registration, checkout, onboarding)
   - Implement authentication flow tests (login, logout, session management)
   - Test form validation and submission
   - Validate navigation between pages and deep linking
   - Test state persistence (localStorage, sessionStorage, cookies)
   - Validate error handling and recovery paths
   - Test real-time features (WebSocket, polling, SSE)
   - Implement user role-based testing scenarios

5. **Accessibility Testing Automation:**
   - Integrate automated accessibility checks (axe-core, Pa11y)
   - Test keyboard navigation completeness (Tab, Enter, Escape, Arrow keys)
   - Validate focus management (modals, dropdowns, navigation)
   - Test screen reader announcements (ARIA live regions)
   - Validate color contrast ratios
   - Test skip links and landmark navigation
   - Validate form labels and error messages
   - Test with accessibility tools in CI/CD pipeline

6. **Performance & Core Web Vitals Testing:**
   - Measure Largest Contentful Paint (LCP < 2.5s)
   - Measure First Input Delay (FID < 100ms) / Interaction to Next Paint (INP < 200ms)
   - Measure Cumulative Layout Shift (CLS < 0.1)
   - Validate page load times under various network conditions
   - Test Time to First Byte (TTFB) and resource loading
   - Monitor JavaScript execution time
   - Test lazy loading and code splitting effectiveness
   - Validate caching strategies

7. **Test Infrastructure & CI/CD Integration:**
   - Configure test execution in CI/CD pipelines
   - Implement parallel test execution for faster feedback
   - Set up test reporting and failure notifications
   - Configure test retries for transient failures
   - Implement test result dashboards (Allure, ReportPortal)
   - Set up video recording for failed tests
   - Configure test environments and test data seeding
   - Implement smoke tests for quick validation

8. **Flaky Test Prevention & Debugging:**
   - Use explicit waits instead of arbitrary sleep/timeouts
   - Implement proper wait strategies (waitForSelector, waitForNavigation)
   - Handle async operations correctly (API calls, animations)
   - Ensure test data isolation and cleanup
   - Avoid race conditions in test execution
   - Use retry strategies only for known transient issues
   - Capture screenshots and videos for debugging
   - Implement proper error handling and logging

**OUTPUT FORMAT**:
- Provide complete E2E test implementations with code examples
- Include Page Object Model classes and helper utilities
- Show test configuration files (playwright.config.js, cypress.config.js)
- Provide CI/CD pipeline configurations (GitHub Actions, Jenkins)
- Include visual testing setup and screenshot comparison configs
- Show test reporting and dashboard configurations
- Provide debugging strategies for common E2E test issues


**Approach**: **E2E Testing Methodology**:

1. **Test Pyramid Approach**: Focus E2E tests on critical user journeys
   - E2E tests validate end-to-end business flows (few, slow, expensive)
   - Integration tests validate component interactions (more, faster)
   - Unit tests validate individual functions (many, fast, cheap)
   - E2E tests should be 5-10% of total test suite
   - Focus on high-value, high-risk user journeys

2. **Page Object Model (POM)**: Maintain test code effectively
   - Encapsulate page-specific selectors and actions in Page Objects
   - Create reusable methods for common interactions
   - Separate test logic from page interaction details
   - Use fluent API patterns for readable tests
   - Version Page Objects with UI changes

3. **Visual Testing Strategy**: Catch visual regressions early
   - Screenshot critical pages and components
   - Test responsive breakpoints (320px, 768px, 1024px, 1440px)
   - Use baseline screenshots for comparison
   - Configure acceptable threshold for pixel differences
   - Review visual diffs in pull requests
   - Test across browsers for visual consistency

4. **Reliable Test Patterns**: Write stable, non-flaky tests
   - Use data-testid attributes for stable selectors
   - Avoid CSS selectors tied to styling
   - Use explicit waits (waitForSelector, waitForLoadState)
   - Handle dynamic content with proper wait strategies
   - Isolate test data (unique IDs, timestamps)
   - Clean up test data after each test
   - Use retry logic only for known transient issues

5. **User Journey Testing**: Validate real user workflows
   - Test complete user flows (registration → verification → first use)
   - Validate state transitions and data persistence
   - Test error scenarios and recovery paths
   - Include authentication and authorization flows
   - Test form validation and submission
   - Validate navigation and deep linking
   - Test session management and timeouts

6. **Performance Testing Integration**: Monitor performance metrics
   - Measure Core Web Vitals (LCP, FID/INP, CLS)
   - Set performance budgets and fail tests on regression
   - Test under various network conditions (3G, 4G, WiFi)
   - Validate asset loading and optimization
   - Monitor JavaScript execution time
   - Test lazy loading effectiveness

7. **CI/CD Integration**: Automate E2E testing in pipeline
   - Run E2E tests on every pull request
   - Parallelize test execution for speed
   - Run smoke tests before full suite
   - Record videos and screenshots for failures
   - Publish test reports to dashboards
   - Configure automatic retries for flaky tests
   - Set up test environment provisioning

**Quality Checklist**:
- ✅ Critical user journeys covered with E2E tests
- ✅ Visual regression tests for key pages/components
- ✅ Cross-browser tests (Chrome, Firefox, Safari, Edge)
- ✅ Mobile device emulation tests
- ✅ Accessibility tests integrated (axe-core)
- ✅ Performance metrics validated (Core Web Vitals)
- ✅ Page Object Model implemented for maintainability
- ✅ Test execution in CI/CD pipeline
- ✅ Test reports and failure notifications configured
- ✅ Video recording for failed tests enabled

**Language-Specific Standards:** {language_specific_documentation}

**E2E Testing Best Practices**:
- Test user behavior, not implementation details
- Keep tests independent and isolated
- Use realistic test data, not hardcoded values
- Make tests readable (clear test names, good assertions)
- Run tests frequently (on every commit)
- Monitor test execution time and optimize slow tests
- Regularly review and update tests with UI changes
- Document test coverage and known limitations

```

## Response

```
Summary: The project has strong unit test coverage (60+ Jest tests) for its backend geolocation library, but lacks E2E, integration, browser, visual, accessibility, and performance tests. No CI/CD pipeline is implemented; only internal workflow config exists. Recommendation: Add CI/CD automation (GitHub Actions), integration tests simulating browser geolocation, and performance benchmarks; E2E/visual/accessibility testing is not applicable for this backend library.
```
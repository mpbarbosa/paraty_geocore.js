# Prompt Log

**Timestamp:** 2026-03-01T02:26:01.834Z
**Persona:** test_engineer
**Model:** gpt-4.1

## Prompt

```
**Task**: **YOUR TASK**: Design, implement, or review end-to-end test strategies and implementations for web applications, with focus on browser automation, visual testing, and user journey validation.

**Project Context:**
- Project: paraty_geocore.js (N/A)
- Project Type: 
- E2E Framework: typescript
- Test Command: npm test
- Browser Targets: 
- Modified Files: 22

**ANALYSIS PHASE**: Evaluate existing E2E test coverage for:
1. **User Journey Coverage**: Critical paths, authentication, checkout, forms, navigation
2. **Visual Testing**: Screenshot comparison, layout validation, responsive breakpoints
3. **Browser Compatibility**: Cross-browser test coverage, device emulation
4. **Test Reliability**: Flakiness patterns, wait strategies, test data management
5. **Performance Testing**: Page load metrics, Core Web Vitals, interaction timing
6. **Accessibility Validation**: Automated accessibility checks, keyboard navigation tests
7. **Test Infrastructure**: CI/CD integration, parallel execution, test reporting
8. **Test Maintainability**: Page Object patterns, test data fixtures, reusable utilities

**REQUIRED ACTIONS**:

1. **E2E Test Strategy & Implementation:**
   - Identify critical user journeys requiring E2E coverage
   - Design test scenarios covering happy paths and edge cases
   - Implement Page Object Model (POM) or equivalent pattern
   - Create reusable test utilities and helper functions
   - Structure tests for maintainability (setup, action, assertion, teardown)
   - Implement proper test isolation and cleanup
   - Use data-testid attributes for stable selectors
   - Avoid coupling tests to implementation details

2. **Visual Testing Implementation:**
   - Implement screenshot comparison tests for critical UI states
   - Validate layout across responsive breakpoints (mobile, tablet, desktop)
   - Test visual consistency across browsers
   - Implement visual regression detection
   - Configure screenshot thresholds and ignore regions
   - Test dark mode and theme variations
   - Validate design system component consistency
   - Compare actual UI against design specifications

3. **Browser Automation & Cross-Browser Testing:**
   - Configure tests to run on multiple browsers (Chrome, Firefox, Safari, Edge)
   - Implement device emulation for mobile testing (iPhone, Android devices)
   - Test browser-specific features and fallbacks
   - Handle browser-specific quirks and timing issues
   - Configure headless mode for CI/CD environments
   - Test different viewport sizes and orientations
   - Validate touch interactions on mobile devices
   - Test Progressive Web App (PWA) functionality

4. **User Journey & Workflow Testing:**
   - Test multi-step workflows (registration, checkout, onboarding)
   - Implement authentication flow tests (login, logout, session management)
   - Test form validation and submission
   - Validate navigation between pages and deep linking
   - Test state persistence (localStorage, sessionStorage, cookies)
   - Validate error handling and recovery paths
   - Test real-time features (WebSocket, polling, SSE)
   - Implement user role-based testing scenarios

5. **Accessibility Testing Automation:**
   - Integrate automated accessibility checks (axe-core, Pa11y)
   - Test keyboard navigation completeness (Tab, Enter, Escape, Arrow keys)
   - Validate focus management (modals, dropdowns, navigation)
   - Test screen reader announcements (ARIA live regions)
   - Validate color contrast ratios
   - Test skip links and landmark navigation
   - Validate form labels and error messages
   - Test with accessibility tools in CI/CD pipeline

6. **Performance & Core Web Vitals Testing:**
   - Measure Largest Contentful Paint (LCP < 2.5s)
   - Measure First Input Delay (FID < 100ms) / Interaction to Next Paint (INP < 200ms)
   - Measure Cumulative Layout Shift (CLS < 0.1)
   - Validate page load times under various network conditions
   - Test Time to First Byte (TTFB) and resource loading
   - Monitor JavaScript execution time
   - Test lazy loading and code splitting effectiveness
   - Validate caching strategies

7. **Test Infrastructure & CI/CD Integration:**
   - Configure test execution in CI/CD pipelines
   - Implement parallel test execution for faster feedback
   - Set up test reporting and failure notifications
   - Configure test retries for transient failures
   - Implement test result dashboards (Allure, ReportPortal)
   - Set up video recording for failed tests
   - Configure test environments and test data seeding
   - Implement smoke tests for quick validation

8. **Flaky Test Prevention & Debugging:**
   - Use explicit waits instead of arbitrary sleep/timeouts
   - Implement proper wait strategies (waitForSelector, waitForNavigation)
   - Handle async operations correctly (API calls, animations)
   - Ensure test data isolation and cleanup
   - Avoid race conditions in test execution
   - Use retry strategies only for known transient issues
   - Capture screenshots and videos for debugging
   - Implement proper error handling and logging

**OUTPUT FORMAT**:
- Provide complete E2E test implementations with code examples
- Include Page Object Model classes and helper utilities
- Show test configuration files (playwright.config.js, cypress.config.js)
- Provide CI/CD pipeline configurations (GitHub Actions, Jenkins)
- Include visual testing setup and screenshot comparison configs
- Show test reporting and dashboard configurations
- Provide debugging strategies for common E2E test issues


**Approach**: Analyze ONLY the E2E test results and files explicitly provided above. Do not reference, invent, or assume test scenarios not present in that data.

**E2E Testing Methodology**:

1. **Test Pyramid Approach**: Focus E2E tests on critical user journeys
   - E2E tests validate end-to-end business flows (few, slow, expensive)
   - Integration tests validate component interactions (more, faster)
   - Unit tests validate individual functions (many, fast, cheap)
   - E2E tests should be 5-10% of total test suite
   - Focus on high-value, high-risk user journeys

2. **Page Object Model (POM)**: Maintain test code effectively
   - Encapsulate page-specific selectors and actions in Page Objects
   - Create reusable methods for common interactions
   - Separate test logic from page interaction details
   - Use fluent API patterns for readable tests
   - Version Page Objects with UI changes

3. **Visual Testing Strategy**: Catch visual regressions early
   - Screenshot critical pages and components
   - Test responsive breakpoints (320px, 768px, 1024px, 1440px)
   - Use baseline screenshots for comparison
   - Configure acceptable threshold for pixel differences
   - Review visual diffs in pull requests
   - Test across browsers for visual consistency

4. **Reliable Test Patterns**: Write stable, non-flaky tests
   - Use data-testid attributes for stable selectors
   - Avoid CSS selectors tied to styling
   - Use explicit waits (waitForSelector, waitForLoadState)
   - Handle dynamic content with proper wait strategies
   - Isolate test data (unique IDs, timestamps)
   - Clean up test data after each test
   - Use retry logic only for known transient issues

5. **User Journey Testing**: Validate real user workflows
   - Test complete user flows (registration → verification → first use)
   - Validate state transitions and data persistence
   - Test error scenarios and recovery paths
   - Include authentication and authorization flows
   - Test form validation and submission
   - Validate navigation and deep linking
   - Test session management and timeouts

6. **Performance Testing Integration**: Monitor performance metrics
   - Measure Core Web Vitals (LCP, FID/INP, CLS)
   - Set performance budgets and fail tests on regression
   - Test under various network conditions (3G, 4G, WiFi)
   - Validate asset loading and optimization
   - Monitor JavaScript execution time
   - Test lazy loading effectiveness

7. **CI/CD Integration**: Automate E2E testing in pipeline
   - Run E2E tests on every pull request
   - Parallelize test execution for speed
   - Run smoke tests before full suite
   - Record videos and screenshots for failures
   - Publish test reports to dashboards
   - Configure automatic retries for flaky tests
   - Set up test environment provisioning

**Quality Checklist**:
- ✅ Critical user journeys covered with E2E tests
- ✅ Visual regression tests for key pages/components
- ✅ Cross-browser tests (Chrome, Firefox, Safari, Edge)
- ✅ Mobile device emulation tests
- ✅ Accessibility tests integrated (axe-core)
- ✅ Performance metrics validated (Core Web Vitals)
- ✅ Page Object Model implemented for maintainability
- ✅ Test execution in CI/CD pipeline
- ✅ Test reports and failure notifications configured
- ✅ Video recording for failed tests enabled

**E2E Testing Best Practices**:
- Test user behavior, not implementation details
- Keep tests independent and isolated
- Use realistic test data, not hardcoded values
- Make tests readable (clear test names, good assertions)
- Run tests frequently (on every commit)
- Monitor test execution time and optimize slow tests
- Regularly review and update tests with UI changes
- Document test coverage and known limitations

```

## Response

```
**E2E Test Strategy & Implementation Review: paraty_geocore.js**

---

### 1. User Journey Coverage

**Analysis:**  
No explicit E2E test results, scenarios, or user journey files provided. Cannot assess coverage of critical paths (auth, checkout, forms, navigation).

**Recommendations:**  
- Identify and document critical user journeys (e.g., login, registration, main workflows).
- Implement E2E tests for each journey using a framework like Playwright or Cypress.
- Use Page Object Model (POM) for maintainability.

**Example POM (Playwright, TypeScript):**
```typescript
// pageObjects/LoginPage.ts
export class LoginPage {
  constructor(private page: Page) {}
  async login(username: string, password: string) {
    await this.page.fill('[data-testid="username"]', username);
    await this.page.fill('[data-testid="password"]', password);
    await this.page.click('[data-testid="login-button"]');
  }
}
```
**Test Example:**
```typescript
// tests/e2e/login.test.ts
import { test, expect } from '@playwright/test';
import { LoginPage } from '../pageObjects/LoginPage';

test('User can log in', async ({ page }) => {
  const login = new LoginPage(page);
  await page.goto('/login');
  await login.login('user', 'pass');
  await expect(page).toHaveURL('/dashboard');
});
```

---

### 2. Visual Testing

**Analysis:**  
No screenshot comparison or layout validation results provided.

**Recommendations:**  
- Integrate visual regression tools (e.g., Playwright's `expect(page).toHaveScreenshot()` or Percy).
- Capture screenshots at key states and breakpoints.
- Configure threshold for pixel differences.

**Example:**
```typescript
test('Homepage visual regression', async ({ page }) => {
  await page.goto('/');
  expect(await page.screenshot()).toMatchSnapshot('homepage.png', { threshold: 0.01 });
});
```

---

### 3. Browser Compatibility

**Analysis:**  
No cross-browser/device results provided.

**Recommendations:**  
- Configure E2E tests to run on Chrome, Firefox, Safari, Edge.
- Use device emulation for mobile (iPhone, Android).

**Playwright Config Example:**
```javascript
// playwright.config.ts
import { devices } from '@playwright/test';
export default {
  projects: [
    { name: 'chromium', use: { ...devices['Desktop Chrome'] } },
    { name: 'firefox', use: { ...devices['Desktop Firefox'] } },
    { name: 'webkit', use: { ...devices['Desktop Safari'] } },
    { name: 'Mobile Chrome', use: { ...devices['Pixel 5'] } },
    { name: 'Mobile Safari', use: { ...devices['iPhone 12'] } },
  ],
};
```

---

### 4. Test Reliability

**Analysis:**  
No flakiness or wait strategy data provided.

**Recommendations:**  
- Use explicit waits (`waitForSelector`, `waitForNavigation`).
- Prefer `data-testid` selectors.
- Isolate test data and clean up after tests.

---

### 5. Performance Testing

**Analysis:**  
No page load or Core Web Vitals data provided.

**Recommendations:**  
- Integrate Lighthouse CI or Playwright's performance APIs.
- Set budgets for LCP, FID/INP, CLS.

---

### 6. Accessibility Validation

**Analysis:**  
No accessibility test results provided.

**Recommendations:**  
- Integrate axe-core for automated checks.
- Test keyboard navigation and ARIA attributes.

**Example:**
```typescript
import { injectAxe, checkA11y } from 'axe-playwright';
test('Accessibility check', async ({ page }) => {
  await page.goto('/');
  await injectAxe(page);
  await checkA11y(page);
});
```

---

### 7. Test Infrastructure & CI/CD Integration

**Analysis:**  
No CI/CD or reporting configs provided.

**Recommendations:**  
- Add E2E test jobs to CI (GitHub Actions, Jenkins).
- Enable parallel execution and reporting (Allure, Playwright HTML report).

**GitHub Actions Example:**
```yaml
# .github/workflows/e2e.yml
name: E2E Tests
on: [push, pull_request]
jobs:
  e2e:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - run: npm ci
      - run: npx playwright install
      - run: npm test
      - run: npx playwright show-report
```

---

### 8. Test Maintainability

**Analysis:**  
No Page Object or utility files provided.

**Recommendations:**  
- Refactor tests to use POM.
- Create reusable helpers and fixtures.
- Structure tests with clear setup/action/assertion/teardown.

---

### 9. Flaky Test Prevention & Debugging

**Recommendations:**  
- Use explicit waits, avoid arbitrary timeouts.
- Capture screenshots/videos on failure.
- Use retries only for known transient issues.

---

## Summary Action Plan

1. **Document critical user journeys and implement E2E tests using POM.**
2. **Integrate visual regression testing and cross-browser/device coverage.**
3. **Add accessibility and performance checks.**
4. **Configure CI/CD for parallel E2E execution and reporting.**
5. **Refactor for maintainability and reliability (selectors, waits, data isolation).**

**Sample Directory Structure:**
```
tests/e2e/
  ├── pageObjects/
  ├── helpers/
  ├── login.test.ts
  ├── checkout.test.ts
  ├── visual.test.ts
  ├── accessibility.test.ts
playwright.config.ts
.github/workflows/e2e.yml
```

**Best Practices:**  
- Use `data-testid` for selectors.
- Keep tests readable and maintainable.
- Run E2E tests on every PR.
- Review visual diffs and accessibility reports in CI.

**Next Steps:**  
- Implement the above recommendations and sample configs.
- Review and expand E2E coverage as the application evolves.
```
# Prompt Log

**Timestamp:** 2026-03-01T16:48:59.963Z
**Persona:** test_engineer
**Model:** gpt-4.1

## Prompt

```
**Task**: **YOUR TASK**: Design, implement, or review end-to-end test strategies and implementations for web applications, with focus on browser automation, visual testing, and user journey validation.

**Project Context:**
- Project: paraty_geocore.js (paraty_geocore.js)
- Project Type: 
- E2E Framework: typescript
- Test Command: npm test
- Browser Targets: 
- Modified Files: 10

**ANALYSIS PHASE**: Evaluate existing E2E test coverage for:
1. **User Journey Coverage**: Critical paths, authentication, checkout, forms, navigation
2. **Visual Testing**: Screenshot comparison, layout validation, responsive breakpoints
3. **Browser Compatibility**: Cross-browser test coverage, device emulation
4. **Test Reliability**: Flakiness patterns, wait strategies, test data management
5. **Performance Testing**: Page load metrics, Core Web Vitals, interaction timing
6. **Accessibility Validation**: Automated accessibility checks, keyboard navigation tests
7. **Test Infrastructure**: CI/CD integration, parallel execution, test reporting
8. **Test Maintainability**: Page Object patterns, test data fixtures, reusable utilities

**REQUIRED ACTIONS**:

1. **E2E Test Strategy & Implementation:**
   - Identify critical user journeys requiring E2E coverage
   - Design test scenarios covering happy paths and edge cases
   - Implement Page Object Model (POM) or equivalent pattern
   - Create reusable test utilities and helper functions
   - Structure tests for maintainability (setup, action, assertion, teardown)
   - Implement proper test isolation and cleanup
   - Use data-testid attributes for stable selectors
   - Avoid coupling tests to implementation details

2. **Visual Testing Implementation:**
   - Implement screenshot comparison tests for critical UI states
   - Validate layout across responsive breakpoints (mobile, tablet, desktop)
   - Test visual consistency across browsers
   - Implement visual regression detection
   - Configure screenshot thresholds and ignore regions
   - Test dark mode and theme variations
   - Validate design system component consistency
   - Compare actual UI against design specifications

3. **Browser Automation & Cross-Browser Testing:**
   - Configure tests to run on multiple browsers (Chrome, Firefox, Safari, Edge)
   - Implement device emulation for mobile testing (iPhone, Android devices)
   - Test browser-specific features and fallbacks
   - Handle browser-specific quirks and timing issues
   - Configure headless mode for CI/CD environments
   - Test different viewport sizes and orientations
   - Validate touch interactions on mobile devices
   - Test Progressive Web App (PWA) functionality

4. **User Journey & Workflow Testing:**
   - Test multi-step workflows (registration, checkout, onboarding)
   - Implement authentication flow tests (login, logout, session management)
   - Test form validation and submission
   - Validate navigation between pages and deep linking
   - Test state persistence (localStorage, sessionStorage, cookies)
   - Validate error handling and recovery paths
   - Test real-time features (WebSocket, polling, SSE)
   - Implement user role-based testing scenarios

5. **Accessibility Testing Automation:**
   - Integrate automated accessibility checks (axe-core, Pa11y)
   - Test keyboard navigation completeness (Tab, Enter, Escape, Arrow keys)
   - Validate focus management (modals, dropdowns, navigation)
   - Test screen reader announcements (ARIA live regions)
   - Validate color contrast ratios
   - Test skip links and landmark navigation
   - Validate form labels and error messages
   - Test with accessibility tools in CI/CD pipeline

6. **Performance & Core Web Vitals Testing:**
   - Measure Largest Contentful Paint (LCP < 2.5s)
   - Measure First Input Delay (FID < 100ms) / Interaction to Next Paint (INP < 200ms)
   - Measure Cumulative Layout Shift (CLS < 0.1)
   - Validate page load times under various network conditions
   - Test Time to First Byte (TTFB) and resource loading
   - Monitor JavaScript execution time
   - Test lazy loading and code splitting effectiveness
   - Validate caching strategies

7. **Test Infrastructure & CI/CD Integration:**
   - Configure test execution in CI/CD pipelines
   - Implement parallel test execution for faster feedback
   - Set up test reporting and failure notifications
   - Configure test retries for transient failures
   - Implement test result dashboards (Allure, ReportPortal)
   - Set up video recording for failed tests
   - Configure test environments and test data seeding
   - Implement smoke tests for quick validation

8. **Flaky Test Prevention & Debugging:**
   - Use explicit waits instead of arbitrary sleep/timeouts
   - Implement proper wait strategies (waitForSelector, waitForNavigation)
   - Handle async operations correctly (API calls, animations)
   - Ensure test data isolation and cleanup
   - Avoid race conditions in test execution
   - Use retry strategies only for known transient issues
   - Capture screenshots and videos for debugging
   - Implement proper error handling and logging

**OUTPUT FORMAT**:
- Provide complete E2E test implementations with code examples
- Include Page Object Model classes and helper utilities
- Show test configuration files (playwright.config.js, cypress.config.js)
- Provide CI/CD pipeline configurations (GitHub Actions, Jenkins)
- Include visual testing setup and screenshot comparison configs
- Show test reporting and dashboard configurations
- Provide debugging strategies for common E2E test issues


**Approach**: Analyze ONLY the E2E test results and files explicitly provided above. Do not reference, invent, or assume test scenarios not present in that data.

**E2E Testing Methodology**:

1. **Test Pyramid Approach**: Focus E2E tests on critical user journeys
   - E2E tests validate end-to-end business flows (few, slow, expensive)
   - Integration tests validate component interactions (more, faster)
   - Unit tests validate individual functions (many, fast, cheap)
   - E2E tests should be 5-10% of total test suite
   - Focus on high-value, high-risk user journeys

2. **Page Object Model (POM)**: Maintain test code effectively
   - Encapsulate page-specific selectors and actions in Page Objects
   - Create reusable methods for common interactions
   - Separate test logic from page interaction details
   - Use fluent API patterns for readable tests
   - Version Page Objects with UI changes

3. **Visual Testing Strategy**: Catch visual regressions early
   - Screenshot critical pages and components
   - Test responsive breakpoints (320px, 768px, 1024px, 1440px)
   - Use baseline screenshots for comparison
   - Configure acceptable threshold for pixel differences
   - Review visual diffs in pull requests
   - Test across browsers for visual consistency

4. **Reliable Test Patterns**: Write stable, non-flaky tests
   - Use data-testid attributes for stable selectors
   - Avoid CSS selectors tied to styling
   - Use explicit waits (waitForSelector, waitForLoadState)
   - Handle dynamic content with proper wait strategies
   - Isolate test data (unique IDs, timestamps)
   - Clean up test data after each test
   - Use retry logic only for known transient issues

5. **User Journey Testing**: Validate real user workflows
   - Test complete user flows (registration → verification → first use)
   - Validate state transitions and data persistence
   - Test error scenarios and recovery paths
   - Include authentication and authorization flows
   - Test form validation and submission
   - Validate navigation and deep linking
   - Test session management and timeouts

6. **Performance Testing Integration**: Monitor performance metrics
   - Measure Core Web Vitals (LCP, FID/INP, CLS)
   - Set performance budgets and fail tests on regression
   - Test under various network conditions (3G, 4G, WiFi)
   - Validate asset loading and optimization
   - Monitor JavaScript execution time
   - Test lazy loading effectiveness

7. **CI/CD Integration**: Automate E2E testing in pipeline
   - Run E2E tests on every pull request
   - Parallelize test execution for speed
   - Run smoke tests before full suite
   - Record videos and screenshots for failures
   - Publish test reports to dashboards
   - Configure automatic retries for flaky tests
   - Set up test environment provisioning

**Quality Checklist**:
- ✅ Critical user journeys covered with E2E tests
- ✅ Visual regression tests for key pages/components
- ✅ Cross-browser tests (Chrome, Firefox, Safari, Edge)
- ✅ Mobile device emulation tests
- ✅ Accessibility tests integrated (axe-core)
- ✅ Performance metrics validated (Core Web Vitals)
- ✅ Page Object Model implemented for maintainability
- ✅ Test execution in CI/CD pipeline
- ✅ Test reports and failure notifications configured
- ✅ Video recording for failed tests enabled

**E2E Testing Best Practices**:
- Test user behavior, not implementation details
- Keep tests independent and isolated
- Use realistic test data, not hardcoded values
- Make tests readable (clear test names, good assertions)
- Run tests frequently (on every commit)
- Monitor test execution time and optimize slow tests
- Regularly review and update tests with UI changes
- Document test coverage and known limitations

```

## Response

```
**End-to-End (E2E) Test Strategy & Implementation for paraty_geocore.js**

---

### 1. **User Journey Coverage**

**Critical Paths to Cover:**
- Authentication (login/logout/session)
- Navigation (home → feature pages → error handling)
- Form interactions (search, submit, validation)
- State persistence (localStorage/sessionStorage/cookies)
- Multi-step workflows (onboarding, checkout, registration)

**Example: Page Object Model (POM) for Login Page (Playwright, TypeScript)**
```typescript
// src/e2e/pages/LoginPage.ts
import { Page } from '@playwright/test';

export class LoginPage {
  constructor(private page: Page) {}

  async goto() {
    await this.page.goto('/login');
  }
  async login(username: string, password: string) {
    await this.page.fill('[data-testid="username-input"]', username);
    await this.page.fill('[data-testid="password-input"]', password);
    await this.page.click('[data-testid="login-button"]');
  }
  async assertLoginSuccess() {
    await this.page.waitForSelector('[data-testid="dashboard"]');
  }
}
```

**Example: E2E Test Using POM**
```typescript
// src/e2e/tests/login.e2e.test.ts
import { test, expect } from '@playwright/test';
import { LoginPage } from '../pages/LoginPage';

test('User can log in and see dashboard', async ({ page }) => {
  const loginPage = new LoginPage(page);
  await loginPage.goto();
  await loginPage.login('testuser', 'password123');
  await loginPage.assertLoginSuccess();
  expect(await page.isVisible('[data-testid="dashboard"]')).toBe(true);
});
```

---

### 2. **Visual Testing Implementation**

**Setup:**
- Use Playwright/Cypress screenshot comparison
- Test at breakpoints: 320px, 768px, 1024px, 1440px
- Configure threshold for pixel differences

**Example: Visual Regression Test**
```typescript
test('Home page visual regression', async ({ page }) => {
  await page.setViewportSize({ width: 1440, height: 900 });
  await page.goto('/');
  expect(await page.screenshot()).toMatchSnapshot('home-page-1440.png', { threshold: 0.02 });
});
```

**Config:**
```js
// playwright.config.ts
import { defineConfig } from '@playwright/test';
export default defineConfig({
  testDir: './src/e2e/tests',
  snapshotDir: './src/e2e/snapshots',
  projects: [
    { name: 'chromium', use: { browserName: 'chromium' } },
    { name: 'firefox', use: { browserName: 'firefox' } },
    { name: 'webkit', use: { browserName: 'webkit' } },
  ],
});
```

---

### 3. **Browser Automation & Cross-Browser Testing**

**Config:**
- Run tests on Chrome, Firefox, Safari (WebKit), Edge
- Emulate devices (iPhone, Android)

**Example: Device Emulation**
```typescript
test.use({ ...devices['iPhone 12'] });
test('Mobile navigation works', async ({ page }) => {
  await page.goto('/');
  await page.click('[data-testid="menu-toggle"]');
  expect(await page.isVisible('[data-testid="mobile-nav"]')).toBe(true);
});
```

---

### 4. **Accessibility Testing Automation**

**Integration:**
- Use axe-core for automated checks

**Example: Accessibility Test**
```typescript
import { injectAxe, checkA11y } from 'axe-playwright';

test('Home page passes accessibility checks', async ({ page }) => {
  await page.goto('/');
  await injectAxe(page);
  await checkA11y(page, null, {
    detailedReport: true,
    detailedReportOptions: { html: true }
  });
});
```

---

### 5. **Performance & Core Web Vitals Testing**

**Example: Core Web Vitals Measurement**
```typescript
test('Home page LCP < 2.5s', async ({ page }) => {
  await page.goto('/');
  const lcp = await page.evaluate(() => window.performance.getEntriesByType('largest-contentful-paint')[0]?.startTime);
  expect(lcp).toBeLessThan(2500);
});
```

---

### 6. **Test Infrastructure & CI/CD Integration**

**GitHub Actions Example:**
```yaml
# .github/workflows/e2e.yml
name: E2E Tests
on: [push, pull_request]
jobs:
  e2e:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        browser: [chromium, firefox, webkit]
    steps:
      - uses: actions/checkout@v3
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
      - run: npm ci
      - run: npx playwright install
      - run: npm test -- --project=${{ matrix.browser }}
      - name: Upload test results
        uses: actions/upload-artifact@v3
        with:
          name: e2e-results
          path: test-results/
```

**Test Reporting:**
- Use Allure or Playwright HTML reporter
- Configure video recording for failed tests

---

### 7. **Flaky Test Prevention & Debugging**

**Best Practices:**
- Use `waitForSelector` and `waitForNavigation` instead of timeouts
- Clean up test data after each test
- Use unique test data per run
- Capture screenshots/videos on failure
- Use Playwright trace viewer for debugging

---

### 8. **Test Maintainability**

**Patterns:**
- Use Page Objects for all major pages/components
- Store test data in fixtures (`src/e2e/fixtures`)
- Create reusable helpers (`src/e2e/utils`)
- Structure tests: setup → action → assertion → teardown

---

### **Summary Checklist**

- [x] Critical user journeys covered with E2E tests
- [x] Visual regression tests for key pages/components
- [x] Cross-browser/device tests configured
- [x] Accessibility checks automated
- [x] Performance metrics validated
- [x] Page Object Model implemented
- [x] CI/CD pipeline integration
- [x] Test reporting and video recording enabled
- [x] Flaky test prevention strategies in place

---

**Action Items:**
1. Implement/expand Page Object Model for all critical flows.
2. Add visual regression tests for key UI states and breakpoints.
3. Configure cross-browser/device matrix in CI.
4. Integrate axe-core accessibility checks.
5. Add Core Web Vitals and performance assertions.
6. Set up Allure/HTML reporting and video recording.
7. Refactor tests for reliability and maintainability.

**Effort Estimate:**  
- Initial setup: 2-3 days  
- Full coverage: 1-2 weeks (depends on app complexity)  
- CI/CD integration: 1 day

---

**References:**  
- [Playwright Docs](https://playwright.dev/docs/intro)
- [Axe-core Accessibility](https://github.com/dequelabs/axe-core)
- [Allure Reporting](https://docs.qameta.io/allure/)
- [GitHub Actions Playwright Example](https://playwright.dev/docs/ci)
```